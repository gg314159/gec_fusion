{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnet50 cross attention baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\" \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import hiddenlayer as hl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD,Adam\n",
    "import torch.utils.data as Data\n",
    "from torchvision import models\n",
    "from  torchvision import transforms\n",
    "from  torchvision.datasets import ImageFolder\n",
    "import pickle as pkl\n",
    "import torchvision.models as models\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuneResnet50(nn.Module):\n",
    "    def __init__(self, num_class=3):\n",
    "        super(FineTuneResnet50, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        resnet50_net_MRI = models.resnet50(pretrained=True)\n",
    "        resnet50_net_PET = models.resnet50(pretrained=True)\n",
    "        self.features_MRI = nn.Sequential(*list(resnet50_net_MRI.children())[:-1])\n",
    "        self.features_PET = nn.Sequential(*list(resnet50_net_PET.children())[:-1])\n",
    "        self.fc_comb = nn.Sequential(\n",
    "            nn.Linear(4096,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(128,3)\n",
    "        )\n",
    "        \n",
    "         \n",
    "    def MA(self, x, label):\n",
    "        # x (k, v), label (q)\n",
    "        B, C_kv = x.shape\n",
    "        B, C_q = label.shape\n",
    "        self.kv = nn.Linear(C_kv, C_kv * 3 * 2).cuda()\n",
    "        self.q = nn.Linear(C_q, C_kv * 3).cuda()\n",
    "        self.at_fx = nn.Linear(C_kv * 3, C_kv).cuda()\n",
    "        #self.ffn = nn.Linear(C_kv, C_kv).cuda()\n",
    "        kv = self.kv(x).reshape(2, B, 3, C_kv)\n",
    "        k, v = kv[0], kv[1]\n",
    "        q = self.q(label).reshape(B, 3, C_kv)\n",
    "        attn = torch.einsum(\"bhq,bhk->bhqk\", [q, k])\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        x_ = torch.einsum(\"bhqk,bhk->bhq\", [attn, v])\n",
    "        x_ = x_.reshape(B, C_kv * 3)\n",
    "        x = self.at_fx(x_) + x\n",
    "        #x = self.ffn(x) + x\n",
    "        return x    \n",
    "        \n",
    "\n",
    " \n",
    "    def forward(self, MRI,PET):\n",
    "        MRI = self.features_MRI(MRI)\n",
    "        PET = self.features_PET(PET)\n",
    "        MRI = MRI.view(MRI.size(0),-1)\n",
    "        PET = PET.view(PET.size(0),-1)# 将第二次卷积的输出拉伸为一行\n",
    "        \n",
    "        MRI_ma = self.MA(MRI,PET)\n",
    "        PET_ma = self.MA(PET,MRI)\n",
    "        MRI = torch.cat((MRI_ma, PET_ma), 1)\n",
    "        MRI = self.fc_comb(MRI)\n",
    "        return MRI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyResnet = FineTuneResnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuneResnet50(\n",
       "  (features_MRI): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (features_PET): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (fc_comb): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyResnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义优化器\n",
    "optimizer = torch.optim.Adam(MyResnet.parameters(),lr=0.00001,weight_decay=0.01)\n",
    "loss_func = nn.CrossEntropyLoss()#损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#记录训练过程指标\n",
    "historyl = hl.History()\n",
    "#使用Canves进行可视化\n",
    "\n",
    "canvasl = hl.Canvas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root):\n",
    "        super(MyDataset, self).__init__()\n",
    "        MRI_PET_match_all = pkl.load(open(root,\"rb\"),encoding='iso-8859-1')\n",
    "        MRI = []\n",
    "        PET = []\n",
    "        group = []\n",
    "        for index,row in MRI_PET_match_all.iterrows():\n",
    "            MRI.append(row['MRI_img_array'])\n",
    "            PET.append(row['PET_img_array'])\n",
    "            group_ = torch.tensor(row['Group'],dtype=torch.float)\n",
    "            group.append(group_)\n",
    "        self.MRI = MRI\n",
    "        self.PET = PET\n",
    "        self.group = group  \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        mri =torch.from_numpy(self.MRI[index].transpose([2,0,1])).float().to(DEVICE)\n",
    "        pet = torch.from_numpy(self.PET[index].transpose([2,0,1])).float().to(DEVICE)\n",
    "        group = self.group[index].to(DEVICE)\n",
    "        return mri,pet,group\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.MRI)\n",
    "\n",
    "train_data = MyDataset(\"/home/gc/gechang/gec_multi_fusion/end_to_end/train.pkl\")\n",
    "test_data = MyDataset(\"/home/gc/gechang/gec_multi_fusion/end_to_end/test.pkl\")\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "epoch: 0 train_loss: 1.0000896543600928 train_acc: tensor(0.5533, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 0 val_loss: 0.9738983535766601 val_acc: tensor(0.5450, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 1 train_loss: 0.871044895879298 train_acc: tensor(0.5885, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 1 val_loss: 0.8790412139892578 val_acc: tensor(0.5550, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 2 train_loss: 0.6854362866211416 train_acc: tensor(0.7390, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 2 val_loss: 0.7578091204166413 val_acc: tensor(0.6050, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 3 train_loss: 0.4971851312755192 train_acc: tensor(0.8432, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 3 val_loss: 0.6147321951389313 val_acc: tensor(0.7600, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 4 train_loss: 0.3612666066497602 train_acc: tensor(0.8883, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 4 val_loss: 0.5826648926734924 val_acc: tensor(0.7900, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 5 train_loss: 0.29638681473815753 train_acc: tensor(0.9222, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 5 val_loss: 0.5142083066701889 val_acc: tensor(0.8000, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 6 train_loss: 0.23827620523711818 train_acc: tensor(0.9561, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 6 val_loss: 0.48831728011369707 val_acc: tensor(0.8200, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 7 train_loss: 0.18165126111980065 train_acc: tensor(0.9711, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 7 val_loss: 0.47008962124586107 val_acc: tensor(0.8150, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 8 train_loss: 0.12598125380434685 train_acc: tensor(0.9862, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 8 val_loss: 0.4459178845584393 val_acc: tensor(0.8050, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 9 train_loss: 0.12067634896392766 train_acc: tensor(0.9824, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 9 val_loss: 0.6263457918167115 val_acc: tensor(0.7600, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 10 train_loss: 0.09574750338773357 train_acc: tensor(0.9849, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 10 val_loss: 0.46310712352395056 val_acc: tensor(0.8100, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 11 train_loss: 0.08395159507691487 train_acc: tensor(0.9849, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 11 val_loss: 0.5203297010995448 val_acc: tensor(0.8050, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 12 train_loss: 0.1115361378718649 train_acc: tensor(0.9787, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 12 val_loss: 0.5114520416036248 val_acc: tensor(0.8050, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 13 train_loss: 0.0785042544291676 train_acc: tensor(0.9837, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 13 val_loss: 0.6135447673872113 val_acc: tensor(0.7700, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 14 train_loss: 0.06739168025674754 train_acc: tensor(0.9849, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 14 val_loss: 0.571141391582787 val_acc: tensor(0.7650, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 15 train_loss: 0.08933955963369146 train_acc: tensor(0.9824, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 15 val_loss: 0.5720887754112483 val_acc: tensor(0.8350, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 16 train_loss: 0.10452803999297741 train_acc: tensor(0.9749, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 16 val_loss: 0.5523053253255784 val_acc: tensor(0.8300, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 17 train_loss: 0.09107059731593395 train_acc: tensor(0.9774, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 17 val_loss: 0.5528488892130554 val_acc: tensor(0.8150, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 18 train_loss: 0.05765724458838048 train_acc: tensor(0.9849, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 18 val_loss: 0.6268368603661656 val_acc: tensor(0.7700, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 19 train_loss: 0.04928515681358921 train_acc: tensor(0.9912, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 19 val_loss: 0.6522751216497272 val_acc: tensor(0.8000, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 20 train_loss: 0.04514118339609322 train_acc: tensor(0.9925, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 20 val_loss: 0.4967175344377756 val_acc: tensor(0.8350, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 21 train_loss: 0.04442531084513275 train_acc: tensor(0.9912, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 21 val_loss: 0.5385249911621213 val_acc: tensor(0.7900, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 22 train_loss: 0.03777138398284819 train_acc: tensor(0.9900, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 22 val_loss: 0.6804694016184658 val_acc: tensor(0.7800, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 23 train_loss: 0.03127288925046641 train_acc: tensor(0.9925, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 23 val_loss: 0.6145598097704351 val_acc: tensor(0.7950, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 24 train_loss: 0.07011963784521728 train_acc: tensor(0.9837, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 24 val_loss: 0.510731332669966 val_acc: tensor(0.8150, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 25 train_loss: 0.0667188973861327 train_acc: tensor(0.9900, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 25 val_loss: 0.5123135070782154 val_acc: tensor(0.8200, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 26 train_loss: 0.05448421044216738 train_acc: tensor(0.9849, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 26 val_loss: 0.5496614173334092 val_acc: tensor(0.8250, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 27 train_loss: 0.04400294783105665 train_acc: tensor(0.9862, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 27 val_loss: 0.5634743195120245 val_acc: tensor(0.8250, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 28 train_loss: 0.02643913723916339 train_acc: tensor(0.9950, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 28 val_loss: 0.5082045444939286 val_acc: tensor(0.8350, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 29 train_loss: 0.020593198430531635 train_acc: tensor(0.9975, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 29 val_loss: 0.6421755287749693 val_acc: tensor(0.8050, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 30 train_loss: 0.027503805007748166 train_acc: tensor(0.9950, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 30 val_loss: 0.6581904057972133 val_acc: tensor(0.7850, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 31 train_loss: 0.03735632950222702 train_acc: tensor(0.9900, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 31 val_loss: 0.6355953110847622 val_acc: tensor(0.8100, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 32 train_loss: 0.07097280802324396 train_acc: tensor(0.9799, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 32 val_loss: 0.6311315432377159 val_acc: tensor(0.7900, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 33 train_loss: 0.05521346388999349 train_acc: tensor(0.9812, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 33 val_loss: 0.6965684890560806 val_acc: tensor(0.7650, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 34 train_loss: 0.05387639351203159 train_acc: tensor(0.9824, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 34 val_loss: 0.5652432247856631 val_acc: tensor(0.8300, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 35 train_loss: 0.0320088159491003 train_acc: tensor(0.9925, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 35 val_loss: 0.508491584090516 val_acc: tensor(0.8300, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 36 train_loss: 0.032323857294944774 train_acc: tensor(0.9912, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 36 val_loss: 0.6196225061360746 val_acc: tensor(0.7900, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 37 train_loss: 0.024363185898102865 train_acc: tensor(0.9962, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 37 val_loss: 0.6040026593115181 val_acc: tensor(0.8050, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 38 train_loss: 0.07991382521150664 train_acc: tensor(0.9799, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 38 val_loss: 0.692859712978825 val_acc: tensor(0.7900, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "epoch: 39 train_loss: 0.050668027052139325 train_acc: tensor(0.9875, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 39 val_loss: 0.49084504681639374 val_acc: tensor(0.8350, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#对模型进行迭代训练，对所有的数据训练epoch轮\n",
    "for epoch in range(40):\n",
    "    train_loss_epoch = 0\n",
    "    val_loss_epoch = 0\n",
    "    train_corrects = 0\n",
    "    val_corrects = 0\n",
    "    #对训练数据的加载器进行迭代计算\n",
    "    MyResnet.train().cuda()\n",
    "    for step,(mri,pet,group) in enumerate(train_loader):\n",
    "        ##计算每个batch的损失\n",
    "        output = MyResnet(mri,pet)\n",
    "        loss = loss_func(output,group.long())#交叉熵损失函数\n",
    "        pre_lab = torch.argmax(output,1).to(DEVICE)\n",
    "        optimizer.zero_grad()#每个迭代步的梯度初始化为0\n",
    "        loss.backward()#损失的后向传播，计算梯度\n",
    "        optimizer.step()#使用梯度进行优化\n",
    "        train_loss_epoch += loss.item()*group.size(0)\n",
    "        train_corrects += torch.sum(pre_lab == group.to(DEVICE).data)\n",
    "    #计算一个epoch的损失和精度\n",
    "    train_loss = train_loss_epoch/len(train_data.group)\n",
    "    train_acc = train_corrects.double()/len(train_data.group)\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\"epoch:\",epoch,\"train_loss:\",train_loss,\"train_acc:\",train_acc)\n",
    "     #计算在验证集上的表现\n",
    "    MyResnet.eval()\n",
    "    for step,(mri,pet,group) in enumerate(test_loader):\n",
    "        output = MyResnet(mri,pet)\n",
    "        loss = loss_func(output,group.long())\n",
    "        pre_lab = torch.argmax(output,1).to(DEVICE)\n",
    "        val_loss_epoch += loss.item()*group.size(0)\n",
    "        val_corrects += torch.sum(pre_lab == group.to(DEVICE).data)\n",
    "\n",
    "    #计算一个epoch上的输出loss和acc\n",
    "    val_loss = val_loss_epoch/len(test_data.group)\n",
    "    val_acc = val_corrects.double()/len(test_data.group)\n",
    "    print(\"epoch:\",epoch,\"val_loss:\",val_loss,\"val_acc:\",val_acc)\n",
    "    #保存每个epoch上的输出loss和acc\n",
    "    historyl.log(epoch,train_loss=train_loss,val_loss = val_loss,train_acc = train_acc.item(),val_acc = val_acc.item())\n",
    "    #可视化网络训练的过程\n",
    "    # with canvasl:\n",
    "    #     canvasl.draw_plot([historyl[\"train_loss\"],historyl[\"val_loss\"]])\n",
    "    #     canvasl.draw_plot([historyl[\"train_acc\"],historyl[\"val_acc\"]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('py372')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9e0e02a671462d396ecc20af6161881d6338b1e899f7d69a261eb7f1f955476"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
