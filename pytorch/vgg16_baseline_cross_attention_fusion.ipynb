{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline result fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import hiddenlayer as hl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD,Adam\n",
    "import torch.utils.data as Data\n",
    "from torchvision import models\n",
    "from  torchvision import transforms\n",
    "from  torchvision.datasets import ImageFolder\n",
    "import pickle as pkl\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)\n",
    "#获取VGG16的特征提取层\n",
    "vgg = vgg16.features\n",
    "feature = list(vgg)[:30]\n",
    "#获取VGG16的分类层\n",
    "classify = vgg16.classifier\n",
    "classifier = list(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in feature[:24]:\n",
    "    for p in layer.parameters():\n",
    "        p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_1 = nn.Sequential(*feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyVggModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyVggModel,self).__init__()\n",
    "        #预训练的Vgg16的特征提取层\n",
    "        self.vgg_MRI = vgg16_1\n",
    "        self.vgg_PET = vgg16_1\n",
    "        #添加新的全连接层\n",
    "        self.classifier_MRI = nn.Sequential(\n",
    "            nn.Linear(304128,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            #nn.Linear(128,3)\n",
    "\n",
    "        )\n",
    "        self.classifier_PET = nn.Sequential(\n",
    "            nn.Linear(304128,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            #nn.Linear(128,3)\n",
    "\n",
    "        )\n",
    "        self.fc_comb = nn.Sequential(\n",
    "            nn.Linear(256,3)\n",
    "        )\n",
    "        \n",
    "    def MA(self, x, label):\n",
    "        # x (k, v), label (q)\n",
    "        B, C_kv = x.shape\n",
    "        B, C_q = label.shape\n",
    "        self.kv = nn.Linear(C_kv, C_kv * 3 * 2).cuda()\n",
    "        self.q = nn.Linear(C_q, C_kv * 3).cuda()\n",
    "        self.at_fx = nn.Linear(C_kv * 3, C_kv).cuda()\n",
    "        #self.ffn = nn.Linear(C_kv, C_kv).cuda()\n",
    "        kv = self.kv(x).reshape(2, B, 3, C_kv)\n",
    "        k, v = kv[0], kv[1]\n",
    "        q = self.q(label).reshape(B, 3, C_kv)\n",
    "        attn = torch.einsum(\"bhq,bhk->bhqk\", [q, k])\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        x_ = torch.einsum(\"bhqk,bhk->bhq\", [attn, v])\n",
    "        x_ = x_.reshape(B, C_kv * 3)\n",
    "        x = self.at_fx(x_) + x\n",
    "        #x = self.ffn(x) + x\n",
    "        return x    \n",
    "        \n",
    "        \n",
    "    #定义网络的前向传播\n",
    "    def forward(self,MRI,PET):\n",
    "        MRI = self.vgg_MRI(MRI)\n",
    "        PET = self.vgg_PET(PET)\n",
    "        MRI = MRI.view(MRI.size(0),-1)\n",
    "        PET = PET.view(PET.size(0),-1)# 将第二次卷积的输出拉伸为一行\n",
    "        MRI = self.classifier_MRI(MRI)\n",
    "        PET = self.classifier_PET(PET)\n",
    "        \n",
    "        MRI_ma = self.MA(MRI,PET)\n",
    "        PET_ma = self.MA(PET,MRI)\n",
    "        concat = torch.cat((MRI_ma, PET_ma), 1)\n",
    "        output = self.fc_comb(concat)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Myvggc = MyVggModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyVggModel(\n",
       "  (vgg_MRI): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "  )\n",
       "  (vgg_PET): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "  )\n",
       "  (classifier_MRI): Sequential(\n",
       "    (0): Linear(in_features=304128, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (classifier_PET): Sequential(\n",
       "    (0): Linear(in_features=304128, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (fc_comb): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Myvggc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义优化器\n",
    "optimizer = torch.optim.Adam(Myvggc.parameters(),lr=0.00001,weight_decay=0.01)\n",
    "loss_func = nn.CrossEntropyLoss()#损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#记录训练过程指标\n",
    "historyl = hl.History()\n",
    "#使用Canves进行可视化\n",
    "\n",
    "canvasl = hl.Canvas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root):\n",
    "        super(MyDataset, self).__init__()\n",
    "        MRI_PET_match_all = pkl.load(open(root,\"rb\"),encoding='iso-8859-1')\n",
    "        MRI = []\n",
    "        PET = []\n",
    "        group = []\n",
    "        for index,row in MRI_PET_match_all.iterrows():\n",
    "            MRI.append(row['MRI_img_array'])\n",
    "            PET.append(row['PET_img_array'])\n",
    "            group.append(row['Group'])\n",
    "        self.MRI = MRI\n",
    "        self.PET = PET\n",
    "        self.group = group  \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        mri =torch.from_numpy(self.MRI[index].transpose([2,0,1])).float().to(DEVICE)\n",
    "        pet = torch.from_numpy(self.PET[index].transpose([2,0,1])).float().to(DEVICE)\n",
    "        group = self.group[index]\n",
    "        \n",
    "        return mri,pet,group\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.MRI)\n",
    "\n",
    "train_data = MyDataset(\"/home/gc/gechang/gec_multi_fusion/end_to_end/train.pkl\")\n",
    "test_data = MyDataset(\"/home/gc/gechang/gec_multi_fusion/end_to_end/test.pkl\")\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 val_loss: 2.4408586120605467 val_acc: tensor(0.4100, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 1 val_loss: 1.2053029108047486 val_acc: tensor(0.5450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 2 val_loss: 0.9812585115432739 val_acc: tensor(0.5500, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 3 val_loss: 0.9726630401611328 val_acc: tensor(0.5400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 4 val_loss: 0.9679617261886597 val_acc: tensor(0.5450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 5 val_loss: 0.953515830039978 val_acc: tensor(0.5550, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 6 val_loss: 0.9393130493164062 val_acc: tensor(0.5450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 7 val_loss: 0.9179563617706299 val_acc: tensor(0.5800, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 8 val_loss: 0.9025744390487671 val_acc: tensor(0.5750, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 9 val_loss: 0.8734713053703308 val_acc: tensor(0.5950, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 10 val_loss: 0.8463003778457642 val_acc: tensor(0.6000, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 11 val_loss: 0.8244818878173829 val_acc: tensor(0.6350, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 12 val_loss: 0.7922554659843445 val_acc: tensor(0.6250, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 13 val_loss: 0.8236423778533936 val_acc: tensor(0.6250, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 14 val_loss: 0.7783245658874511 val_acc: tensor(0.6650, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 15 val_loss: 0.7410978889465332 val_acc: tensor(0.6900, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 16 val_loss: 0.7259823656082154 val_acc: tensor(0.6900, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 17 val_loss: 0.7399470925331115 val_acc: tensor(0.7050, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 18 val_loss: 0.6969342470169068 val_acc: tensor(0.7100, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 19 val_loss: 0.6810718536376953 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 20 val_loss: 0.6353367590904235 val_acc: tensor(0.7200, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 21 val_loss: 0.6315918159484863 val_acc: tensor(0.7250, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 22 val_loss: 0.6614208936691284 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 23 val_loss: 0.6507152032852173 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 24 val_loss: 0.681706280708313 val_acc: tensor(0.7250, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 25 val_loss: 0.6442908525466919 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 26 val_loss: 0.6803575229644775 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 27 val_loss: 0.6982006072998047 val_acc: tensor(0.7300, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 28 val_loss: 0.639547610282898 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 29 val_loss: 0.7373145580291748 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 30 val_loss: 0.6805534100532532 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 31 val_loss: 0.6334497904777527 val_acc: tensor(0.7450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 32 val_loss: 0.6391077983379364 val_acc: tensor(0.7450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 33 val_loss: 0.6799868440628052 val_acc: tensor(0.7650, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 34 val_loss: 0.7290123414993286 val_acc: tensor(0.7500, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 35 val_loss: 0.7174664688110352 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 36 val_loss: 0.7116964983940125 val_acc: tensor(0.7600, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 37 val_loss: 0.6665947532653809 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 38 val_loss: 0.6842154002189637 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 39 val_loss: 0.7633254671096802 val_acc: tensor(0.7350, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 40 val_loss: 0.7465903043746949 val_acc: tensor(0.7500, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 41 val_loss: 0.7326349329948425 val_acc: tensor(0.7600, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 42 val_loss: 0.8279813599586486 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 43 val_loss: 0.7748875856399536 val_acc: tensor(0.7500, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 44 val_loss: 0.7987267351150513 val_acc: tensor(0.7550, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 45 val_loss: 0.8411783814430237 val_acc: tensor(0.7550, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 46 val_loss: 0.8231454968452454 val_acc: tensor(0.7450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 47 val_loss: 0.8019118857383728 val_acc: tensor(0.7500, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 48 val_loss: 0.7728677654266357 val_acc: tensor(0.7550, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 49 val_loss: 0.7625679695606231 val_acc: tensor(0.7450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 50 val_loss: 0.8083986854553222 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 51 val_loss: 0.9662303161621094 val_acc: tensor(0.7550, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 52 val_loss: 0.8789531087875366 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 53 val_loss: 0.851385407447815 val_acc: tensor(0.7450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 54 val_loss: 0.8270735430717469 val_acc: tensor(0.7300, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 55 val_loss: 0.7733064937591553 val_acc: tensor(0.7500, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 56 val_loss: 0.8672168970108032 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 57 val_loss: 0.7680043816566468 val_acc: tensor(0.7500, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 58 val_loss: 0.8041376686096191 val_acc: tensor(0.7350, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 59 val_loss: 0.760870189666748 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 60 val_loss: 0.8239157009124756 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 61 val_loss: 0.8036733913421631 val_acc: tensor(0.7500, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 62 val_loss: 0.7587279772758484 val_acc: tensor(0.7550, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 63 val_loss: 0.862469561100006 val_acc: tensor(0.7450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 64 val_loss: 0.9504763650894165 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 65 val_loss: 1.051934130191803 val_acc: tensor(0.7350, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 66 val_loss: 0.9478982496261597 val_acc: tensor(0.7550, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 67 val_loss: 0.8267440605163574 val_acc: tensor(0.7550, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 68 val_loss: 0.8558419513702392 val_acc: tensor(0.7550, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 69 val_loss: 0.9839138221740723 val_acc: tensor(0.7300, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 70 val_loss: 0.9659659719467163 val_acc: tensor(0.7350, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 71 val_loss: 0.9129591655731201 val_acc: tensor(0.7350, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 72 val_loss: 0.8748137044906616 val_acc: tensor(0.7450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 73 val_loss: 0.9447562599182129 val_acc: tensor(0.7550, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 74 val_loss: 0.8156013464927674 val_acc: tensor(0.7450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 75 val_loss: 1.0534934139251708 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 76 val_loss: 1.0565520524978638 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 77 val_loss: 1.0255777359008789 val_acc: tensor(0.7450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 78 val_loss: 0.9480329942703247 val_acc: tensor(0.7450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 79 val_loss: 0.8982889413833618 val_acc: tensor(0.7600, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 80 val_loss: 0.9381789541244507 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 81 val_loss: 1.0287080931663513 val_acc: tensor(0.7450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 82 val_loss: 0.9981933069229126 val_acc: tensor(0.7450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 83 val_loss: 1.1815395760536194 val_acc: tensor(0.7450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 84 val_loss: 0.9053089237213134 val_acc: tensor(0.7300, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 85 val_loss: 0.9626623487472534 val_acc: tensor(0.7500, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 86 val_loss: 1.1738759803771972 val_acc: tensor(0.7450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 87 val_loss: 1.2160391426086425 val_acc: tensor(0.7550, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 88 val_loss: 0.9551293182373047 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 89 val_loss: 0.9541929829120636 val_acc: tensor(0.7300, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 90 val_loss: 1.0565249133110046 val_acc: tensor(0.7450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 91 val_loss: 0.9582609701156616 val_acc: tensor(0.7300, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 92 val_loss: 1.0671006226539612 val_acc: tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 93 val_loss: 1.0224715375900268 val_acc: tensor(0.7500, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 94 val_loss: 1.0775394797325135 val_acc: tensor(0.7500, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 95 val_loss: 1.2312760663032531 val_acc: tensor(0.7450, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 96 val_loss: 1.3777420043945312 val_acc: tensor(0.7700, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 97 val_loss: 1.008390815258026 val_acc: tensor(0.7500, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 98 val_loss: 0.925709707736969 val_acc: tensor(0.7300, device='cuda:0', dtype=torch.float64)\n",
      "epoch: 99 val_loss: 1.176757845878601 val_acc: tensor(0.7450, device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#对模型进行迭代训练，对所有的数据训练epoch轮\n",
    "for epoch in range(100):\n",
    "    train_loss_epoch = 0\n",
    "    val_loss_epoch = 0\n",
    "    train_corrects = 0\n",
    "    val_corrects = 0\n",
    "    #对训练数据的加载器进行迭代计算\n",
    "    Myvggc.train().cuda()\n",
    "    for step,(mri,pet,group) in enumerate(train_loader):\n",
    "        ##计算每个batch的损失\n",
    "        output = Myvggc(mri,pet)\n",
    "        loss = loss_func(output,group.to(DEVICE))#交叉熵损失函数\n",
    "        pre_lab = torch.argmax(output,1).to(DEVICE)\n",
    "        optimizer.zero_grad()#每个迭代步的梯度初始化为0\n",
    "        loss.backward()#损失的后向传播，计算梯度\n",
    "        optimizer.step()#使用梯度进行优化\n",
    "        train_loss_epoch += loss.item()*group.size(0)\n",
    "        train_corrects += torch.sum(pre_lab == group.to(DEVICE).data)\n",
    "    #计算一个epoch的损失和精度\n",
    "    train_loss = train_loss_epoch/len(train_data.group)\n",
    "    train_acc = train_corrects.double()/len(train_data.group)\n",
    "    #print(\"epoch:\",epoch,\"train_loss:\",train_loss,\"train_acc:\",train_acc)\n",
    "     #计算在验证集上的表现\n",
    "    Myvggc.eval()\n",
    "    for step,(mri,pet,group) in enumerate(test_loader):\n",
    "        output = Myvggc(mri,pet)\n",
    "        loss = loss_func(output,group.to(DEVICE))\n",
    "        pre_lab = torch.argmax(output,1).to(DEVICE) #返回指定维度最大值的序号下标\n",
    "        val_loss_epoch += loss.item()*group.size(0)\n",
    "        val_corrects += torch.sum(pre_lab == group.to(DEVICE).data)\n",
    "\n",
    "    #计算一个epoch上的输出loss和acc\n",
    "    val_loss = val_loss_epoch/len(test_data.group)\n",
    "    val_acc = val_corrects.double()/len(test_data.group)\n",
    "    print(\"epoch:\",epoch,\"val_loss:\",val_loss,\"val_acc:\",val_acc)\n",
    "    #保存每个epoch上的输出loss和acc\n",
    "    historyl.log(epoch,train_loss=train_loss,val_loss = val_loss,train_acc = train_acc.item(),val_acc = val_acc.item())\n",
    "    #可视化网络训练的过程\n",
    "    # with canvasl:\n",
    "    #     canvasl.draw_plot([historyl[\"train_loss\"],historyl[\"val_loss\"]])\n",
    "    #     canvasl.draw_plot([historyl[\"train_acc\"],historyl[\"val_acc\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(2, 1, 2, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2, 1, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.squeeze(x,1) #只有维数为1的能删，别的不能删\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 1, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('py372')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9e0e02a671462d396ecc20af6161881d6338b1e899f7d69a261eb7f1f955476"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
